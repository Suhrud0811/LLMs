{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'D:\\Learning\\Udemy courses\\Langchain bootcamp\\Notebooks\\.env'\n",
    "load_dotenv(dotenv_path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMessageHistory()\n",
    "memory.add_user_message(\"Hello How are you?\")\n",
    "memory.add_ai_message(\"I am fine, How can I help you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='Hello How are you?', additional_kwargs={}, example=False), AIMessage(content='I am fine, How can I help you?', additional_kwargs={}, example=False)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello How are you?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='I am fine, How can I help you?', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect Conversation to Memory\n",
    "llm = ChatOpenAI()\n",
    "memory = ConversationBufferMemory()\n",
    "chain  = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Nice to meet you\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Nice to meet you too! I am an AI programmed to assist with any questions or tasks you may have. How can I help you today?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"Nice to meet you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Nice to meet you\n",
      "AI: Nice to meet you too! I am an AI programmed to assist with any questions or tasks you may have. How can I help you today?\n",
      "Human: Tell me about Large language models\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Large language models are a type of artificial intelligence that are trained on vast amounts of text data in order to understand and generate human language. These models use deep learning techniques to analyze patterns in text data and learn the relationships between words and phrases. Some popular examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers). These models are often used for tasks such as text generation, translation, summarization, and more. Is there anything specific you would like to know about large language models?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"Tell me about Large language models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Nice to meet you\n",
      "AI: Nice to meet you too! I am an AI programmed to assist with any questions or tasks you may have. How can I help you today?\n",
      "Human: Tell me about Large language models\n",
      "AI: Large language models are a type of artificial intelligence that are trained on vast amounts of text data in order to understand and generate human language. These models use deep learning techniques to analyze patterns in text data and learn the relationships between words and phrases. Some popular examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers). These models are often used for tasks such as text generation, translation, summarization, and more. Is there anything specific you would like to know about large language models?\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: Nice to meet you\\nAI: Nice to meet you too! I am an AI programmed to assist with any questions or tasks you may have. How can I help you today?\\nHuman: Tell me about Large language models\\nAI: Large language models are a type of artificial intelligence that are trained on vast amounts of text data in order to understand and generate human language. These models use deep learning techniques to analyze patterns in text data and learn the relationships between words and phrases. Some popular examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers). These models are often used for tasks such as text generation, translation, summarization, and more. Is there anything specific you would like to know about large language models?'}\n"
     ]
    }
   ],
   "source": [
    "# Incase if we want it as a dictionary\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add extra to memory without calling LLM\n",
    "memory.save_context({\"input\": \"Very Interesting.\"}, \n",
    "                    {\"output\": \"Yes, it was my pleasure as an AI to answer.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: Nice to meet you\\nAI: Nice to meet you too! I am an AI programmed to assist with any questions or tasks you may have. How can I help you today?\\nHuman: Tell me about Large language models\\nAI: Large language models are a type of artificial intelligence that are trained on vast amounts of text data in order to understand and generate human language. These models use deep learning techniques to analyze patterns in text data and learn the relationships between words and phrases. Some popular examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers). These models are often used for tasks such as text generation, translation, summarization, and more. Is there anything specific you would like to know about large language models?\\nHuman: Very Interesting.\\nAI: Yes, it was my pleasure as an AI to answer.'}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving and Loading Memory\n",
    "import pickle\n",
    "pickeled_str = pickle.dumps(chain.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chain_memory.pkl','wb') as f:\n",
    "    f.write(pickeled_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new memory\n",
    "loaded_memory = open('chain_memory.pkl','rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm1 = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = ConversationChain(\n",
    "    llm=llm1,\n",
    "    memory = pickle.loads(loaded_memory),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Nice to meet you\\nAI: Nice to meet you too! I am an AI programmed to assist with any questions or tasks you may have. How can I help you today?\\nHuman: Tell me about Large language models\\nAI: Large language models are a type of artificial intelligence that are trained on vast amounts of text data in order to understand and generate human language. These models use deep learning techniques to analyze patterns in text data and learn the relationships between words and phrases. Some popular examples of large language models include GPT-3 (Generative Pre-trained Transformer 3) and BERT (Bidirectional Encoder Representations from Transformers). These models are often used for tasks such as text generation, translation, summarization, and more. Is there anything specific you would like to know about large language models?\\nHuman: Very Interesting.\\nAI: Yes, it was my pleasure as an AI to answer.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Tell me a fact about Deep Learning\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subset of machine learning that uses artificial neural networks to model and solve complex problems. It is particularly effective in tasks such as image and speech recognition, natural language processing, and autonomous driving. The algorithms in deep learning are inspired by the structure and function of the human brain, with layers of interconnected nodes that process information in a hierarchical manner.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"Tell me a fact about Deep Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell me a fact about Deep Learning\n",
      "AI: Deep learning is a subset of machine learning that uses artificial neural networks to model and solve complex problems. It is particularly effective in tasks such as image and speech recognition, natural language processing, and autonomous driving. The algorithms in deep learning are inspired by the structure and function of the human brain, with layers of interconnected nodes that process information in a hierarchical manner.\n",
      "Human: Tell me a fact about Football\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Football, also known as soccer in some countries, is the most popular sport in the world. It is played by two teams of eleven players each, who try to score goals by kicking a ball into the opposing team's goal. The game is played on a rectangular field with a goal at each end. Football matches are typically played over two halves of 45 minutes each, with additional time added for stoppages. The sport has a rich history and is followed by millions of fans worldwide.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"Tell me a fact about Football\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Tell me a fact about Deep Learning', additional_kwargs={}, example=False), AIMessage(content='Deep learning is a subset of machine learning that uses artificial neural networks to model and solve complex problems. It is particularly effective in tasks such as image and speech recognition, natural language processing, and autonomous driving. The algorithms in deep learning are inspired by the structure and function of the human brain, with layers of interconnected nodes that process information in a hierarchical manner.', additional_kwargs={}, example=False), HumanMessage(content='Tell me a fact about Football', additional_kwargs={}, example=False), AIMessage(content=\"Football, also known as soccer in some countries, is the most popular sport in the world. It is played by two teams of eleven players each, who try to score goals by kicking a ball into the opposing team's goal. The game is played on a rectangular field with a goal at each end. Football matches are typically played over two halves of 45 minutes each, with additional time added for stoppages. The sport has a rich history and is followed by millions of fans worldwide.\", additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)\n",
    "#Note here it saved all the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: Tell me a fact about Football\\nAI: Football, also known as soccer in some countries, is the most popular sport in the world. It is played by two teams of eleven players each, who try to score goals by kicking a ball into the opposing team's goal. The game is played on a rectangular field with a goal at each end. Football matches are typically played over two halves of 45 minutes each, with additional time added for stoppages. The sport has a rich history and is followed by millions of fans worldwide.\"}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))\n",
    "# We can only see last K conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Write me a small Iternary for Paris\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sure! Here is a sample itinerary for a day in Paris:\\n\\n- Morning: Start your day with a visit to the iconic Eiffel Tower. You can take the elevator to the top for stunning views of the city.\\n- Late Morning: Head over to the Louvre Museum to see famous works of art like the Mona Lisa and the Venus de Milo.\\n- Lunch: Enjoy a leisurely lunch at a local cafÃ© and try some delicious French cuisine.\\n- Afternoon: Take a stroll along the Seine River and visit Notre Dame Cathedral.\\n- Evening: End your day with a relaxing cruise on the Seine River to see the city lit up at night.\\n\\nI hope you have a great time in Paris! Let me know if you need any more recommendations.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input = 'Write me a small Iternary for Paris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human asks the AI to create a small itinerary for Paris. The AI provides a sample itinerary for a day in Paris, including visiting the Eiffel Tower, the Louvre Museum, enjoying French cuisine, and more. The AI hopes the human has a great time in Paris and offers more recommendations if needed.\n",
      "Human: What is the best time to watch Northern Lights? \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The best time to watch the Northern Lights is typically during the winter months, from late September to late March. The peak season is usually from December to February when the nights are longest and the sky is darkest. However, the best time also depends on the location you are watching from and the level of solar activity. It's always a good idea to check with local experts or websites for the most up-to-date information on when and where to see the Northern Lights.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input = 'What is the best time to watch Northern Lights? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human asks the AI to create a small itinerary for Paris. The AI provides a sample itinerary for a day in Paris, including visiting the Eiffel Tower, the Louvre Museum, enjoying French cuisine, and more. The AI hopes the human has a great time in Paris and offers more recommendations if needed. The human then asks the AI about the best time to watch the Northern Lights. The AI explains that the best time to watch the Northern Lights is typically during the winter months, from late September to late March, with the peak season usually from December to February. The AI also advises checking with local experts or websites for the most up-to-date information on when and where to see the Northern Lights.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human asks the AI to create a small itinerary for Paris. The AI provides a sample itinerary for a day in Paris, including visiting the Eiffel Tower, the Louvre Museum, enjoying French cuisine, and more. The AI hopes the human has a great time in Paris and offers more recommendations if needed. The human then asks the AI about the best time to watch the Northern Lights. The AI explains that the best time to watch the Northern Lights is typically during the winter months, from late September to late March, with the peak season usually from December to February. The AI also advises checking with local experts or websites for the most up-to-date information on when and where to see the Northern Lights.'}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
